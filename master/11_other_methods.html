

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Other Optimization Methods &mdash; Krotov 1.0.0+dev (3c3d982) documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script type="text/javascript" src="_static/version-menu.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"extensions": ["tex2jax.js"], "jax": ["input/TeX", "output/SVG"], "TeX": {"extensions": ["AMSmath.js", "AMSsymbols.js"], "Macros": {"tr": ["{\\operatorname{tr}}", 0], "diag": ["{\\operatorname{diag}}", 0], "abs": ["{\\operatorname{abs}}", 0], "pop": ["{\\operatorname{pop}}", 0], "ee": ["{\\text{e}}", 0], "ii": ["{\\text{i}}", 0], "aux": ["{\\text{aux}}", 0], "opt": ["{\\text{opt}}", 0], "tgt": ["{\\text{tgt}}", 0], "init": ["{\\text{init}}", 0], "lab": ["{\\text{lab}}", 0], "rwa": ["{\\text{rwa}}", 0], "bra": ["{\\langle#1\\vert}", 1], "ket": ["{\\vert#1\\rangle}", 1], "Bra": ["{\\left\\langle#1\\right\\vert}", 1], "Braket": ["{\\left\\langle #1\\vphantom{#2} \\mid #2\\vphantom{#1}\\right\\rangle}", 2], "ketbra": ["{\\vert#1\\rangle\\!\\langle#2\\vert}", 2], "Ket": ["{\\left\\vert#1\\right\\rangle}", 1], "mat": ["{\\mathbf{#1}}", 1], "op": ["{\\hat{#1}}", 1], "Op": ["{\\hat{#1}}", 1], "dd": ["{\\,\\text{d}}", 0], "daggered": ["{^{\\dagger}}", 0], "transposed": ["{^{\\text{T}}}", 0], "Liouville": ["{\\mathcal{L}}", 0], "DynMap": ["{\\mathcal{E}}", 0], "identity": ["{\\mathbf{1}}", 0], "Norm": ["{\\left\\lVert#1\\right\\rVert}", 1], "norm": ["{\\lVert#1\\rVert}", 1], "Abs": ["{\\left\\vert#1\\right\\vert}", 1], "avg": ["{\\langle#1\\rangle}", 1], "Avg": ["{\\left\\langle#1\\right\\rangle}", 1], "AbsSq": ["{\\left\\vert#1\\right\\vert^2}", 1], "Re": ["{\\operatorname{Re}}", 0], "Im": ["{\\operatorname{Im}}", 0], "Real": ["{\\mathbb{R}}", 0], "Complex": ["{\\mathbb{C}}", 0], "Integer": ["{\\mathbb{N}}", 0]}}, "tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="_static/mycss.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Related Software" href="12_related_software.html" />
    <link rel="prev" title="How-Tos" href="10_howto.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Krotov
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0+dev
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="01_overview.html">Krotov Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_history.html">History</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_krotovs_method.html">Krotov’s Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_qutip_usage.html">Using Krotov with QuTiP</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_howto.html">How-Tos</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Other Optimization Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#iterative-schemes-from-variational-calculus">Iterative schemes from variational calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#krotov-s-method">Krotov’s method</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradient-ascent-pulse-engineering-grape">GRadient Ascent Pulse Engineering (GRAPE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#grape-in-qutip">GRAPE in QuTiP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradient-free-optimization">Gradient-free optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#choosing-an-optimization-method">Choosing an optimization method</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="12_related_software.html">Related Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="99_bibliography.html">References</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="API/krotov.html">API of the Krotov package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Krotov</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          





















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Other Optimization Methods</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="other-optimization-methods">
<h1>Other Optimization Methods<a class="headerlink" href="#other-optimization-methods" title="Permalink to this headline">¶</a></h1>
<p>In the following, we compare Krotov’s method to other numerical
optimization methods that have been used widely in quantum control, with
an emphasis on methods that have been implemented as open source
software.</p>
<div class="section" id="iterative-schemes-from-variational-calculus">
<span id="iterativeschemes"></span><h2>Iterative schemes from variational calculus<a class="headerlink" href="#iterative-schemes-from-variational-calculus" title="Permalink to this headline">¶</a></h2>
<p>Gradient-based optimal control methods derive the condition for the
optimal control field from the application of the variational principle
to the optimization functional in
Eq. <a class="reference internal" href="07_krotovs_method.html#equation-functional">(1)</a>. Since the functional depends
both on the states and the control field, it is necessary to include the
equation of motion (Schrödinger or Liouville-von-Neumann) as a
constraint. That is, the states <span class="math notranslate nohighlight">\(\{\ket{\phi_k}\}\)</span> must be
compatible with the equation of motion under the control fields
<span class="math notranslate nohighlight">\(\{\epsilon_l(t)\}\)</span>. In order to convert the constrained
optimization problem into an unconstrained one, the equation of motion
is included in the functional with the co-states <span class="math notranslate nohighlight">\(\ket{\chi_k(t)}\)</span>
as Lagrange
multipliers <a class="bibtex reference internal" href="99_bibliography.html#kosloffcp1989" id="id1">[61]</a><a class="bibtex reference internal" href="99_bibliography.html#shijcp1990" id="id2">[62]</a><a class="bibtex reference internal" href="99_bibliography.html#shicpc1991" id="id3">[63]</a><a class="bibtex reference internal" href="99_bibliography.html#tannor91" id="id4">[64]</a>.</p>
<p>The necessary condition for an extremum becomes <span class="math notranslate nohighlight">\(\delta J = 0\)</span> for
this extended functional. Evaluation of the extremum condition results
in <a class="bibtex reference internal" href="99_bibliography.html#tannor91" id="id5">[64]</a></p>
<div class="math notranslate nohighlight" id="equation-variational-update">
<span class="eqno">(19)<a class="headerlink" href="#equation-variational-update" title="Permalink to this equation">¶</a></span>\[\Delta \epsilon_l(t) \propto \frac{\delta J}{\delta \epsilon_l} \propto
    \Im \big\langle
    \chi_k(t)
    \big\vert
    \Op{\mu}
    \big\vert
    \phi_k(t)
    \big\rangle\,,\]</div>
<p>where <span class="math notranslate nohighlight">\(\Op{\mu} = \partial \Op{H} / \partial \epsilon_l(t)\)</span> is
the operator coupling to the field <span class="math notranslate nohighlight">\(\epsilon_l(t)\)</span>.
Equation <a class="reference internal" href="#equation-variational-update">(19)</a> is both
continuous in time and implicit in <span class="math notranslate nohighlight">\(\epsilon_l(t)\)</span> since the
states <span class="math notranslate nohighlight">\(\ket{\phi_k(t)}\)</span>, <span class="math notranslate nohighlight">\(\ket{\chi_k(t)}\)</span> also depend on
<span class="math notranslate nohighlight">\(\epsilon_l(t)\)</span>. Numerical solution of
Eq. <a class="reference internal" href="#equation-variational-update">(19)</a> thus requires
an iterative scheme and a choice of time discretization.</p>
<p>The most intuitive time-discretization yields a <em>concurrent</em> update
scheme <a class="bibtex reference internal" href="99_bibliography.html#tannor91" id="id6">[64]</a><a class="bibtex reference internal" href="99_bibliography.html#tannor92" id="id7">[5]</a><a class="bibtex reference internal" href="99_bibliography.html#somloicp1993" id="id8">[44]</a>,</p>
<div class="math notranslate nohighlight" id="equation-concurrent-update">
<span class="eqno">(20)<a class="headerlink" href="#equation-concurrent-update" title="Permalink to this equation">¶</a></span>\[\Delta \epsilon_l^{(i)}(t) \propto
    \Im \big\langle
    \chi_k^{(i-1)}(t)
    \big\vert
    \Op{\mu}
    \big\vert
    \phi_k^{(i-1)}(t)
    \big\rangle\,.\]</div>
<p>Here, at iterative step <span class="math notranslate nohighlight">\((i)\)</span>, the backward-propagated co-states
<span class="math notranslate nohighlight">\(\{\ket{\chi_k(t)}\}\)</span> and the forward-propagated states
<span class="math notranslate nohighlight">\(\{\ket{\phi_k(t)}\}\)</span> both evolve under the ‘guess’ controls
<span class="math notranslate nohighlight">\(\epsilon^{(i-1)}_l(t)\)</span> of that iteration. Thus, the update is
determined entirely by information from the previous iteration and can
be evaluated at each point <span class="math notranslate nohighlight">\(t\)</span> independently. However, this scheme
does not guarantee monotonic convergence, and requires a line search to
determine the appropriate magnitude of the pulse
update <a class="bibtex reference internal" href="99_bibliography.html#tannor91" id="id9">[64]</a>.</p>
<p>A further ad-hoc modification of the
functional <a class="bibtex reference internal" href="99_bibliography.html#zhujcp98" id="id10">[65]</a> allows to formulate a family of
update schemes that do guarantee monotonic
convergence <a class="bibtex reference internal" href="99_bibliography.html#madayjcp2003" id="id11">[66]</a><a class="bibtex reference internal" href="99_bibliography.html#ohtsukijcp2004" id="id12">[67]</a>. These
schemes introduce separate fields <span class="math notranslate nohighlight">\(\{\epsilon_l(t)\}\)</span> and
<span class="math notranslate nohighlight">\(\{\tilde\epsilon_l(t)\}\)</span> for the forward and backward
propagation, respectively, and use the update
scheme <a class="bibtex reference internal" href="99_bibliography.html#werschnikjpb2007" id="id13">[68]</a></p>
<div class="math notranslate nohighlight" id="equation-zhu-rabitz-update">
<span class="eqno">(21)<a class="headerlink" href="#equation-zhu-rabitz-update" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
    \epsilon_l^{(i)}(t)
      &amp; = (1-\delta) \tilde\epsilon_l^{(i-1)}(t) - \frac{\delta}{\alpha}
      \Im \big\langle
        \chi_k^{(i-1)}(t)
        \big\vert
        \Op{\mu}
        \big\vert
        \phi_k^{(i)}(t)
        \big\rangle \\
    \tilde\epsilon_l^{(i)}(t)
      &amp; = (1-\eta) \epsilon_l^{(i-1)}(t) - \frac{\eta}{\alpha}
      \Im \big\langle
        \chi_k^{(i)}(t)
        \big\vert
        \Op{\mu}
        \big\vert
        \phi_k^{(i)}(t)
        \big\rangle\,,
  \end{aligned}\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(\delta, \eta \in [0, 2]\)</span> and an arbitrary step width
<span class="math notranslate nohighlight">\(\alpha\)</span>. For the control of wavepacket dynamics, an
implementation of this generalized class of algorithms is available in
the <a class="reference external" href="https://sourceforge.net/p/wavepacket/wiki/Home/">WavePacket Matlab package</a> <a class="bibtex reference internal" href="99_bibliography.html#schmidtcpc2018" id="id14">[69]</a>.</p>
</div>
<div class="section" id="krotov-s-method">
<span id="comparisonkrotov"></span><h2>Krotov’s method<a class="headerlink" href="#krotov-s-method" title="Permalink to this headline">¶</a></h2>
<p>The method developed by
Krotov <a class="bibtex reference internal" href="99_bibliography.html#krotovec1983" id="id15">[40]</a><a class="bibtex reference internal" href="99_bibliography.html#krotovcc1988" id="id16">[41]</a><a class="bibtex reference internal" href="99_bibliography.html#krotov-book" id="id17">[42]</a><a class="bibtex reference internal" href="99_bibliography.html#konnovarc99" id="id18">[43]</a>
and later translated to the language of quantum control by Tannor and
coworkers <a class="bibtex reference internal" href="99_bibliography.html#tannor92" id="id19">[5]</a><a class="bibtex reference internal" href="99_bibliography.html#somloicp1993" id="id20">[44]</a><a class="bibtex reference internal" href="99_bibliography.html#bartanajcp1997" id="id21">[45]</a><a class="bibtex reference internal" href="99_bibliography.html#sklarzpra2002" id="id22">[46]</a><a class="bibtex reference internal" href="99_bibliography.html#reichjcp12" id="id23">[22]</a>
takes a somewhat unintuitive approach to disentangle the interdependence
of field and states by adding a zero to the functional. This allows to
<em>construct</em> an updated control field that is guaranteed to lower the
value of the functional, resulting in monotonic convergence. The full
method is described in <a class="reference internal" href="07_krotovs_method.html#krotovsmethod"><span class="std std-ref">Krotov’s Method</span></a>, but its essence
can be boiled down to the update in each iteration <span class="math notranslate nohighlight">\((i)\)</span>,
Eq. <a class="reference internal" href="07_krotovs_method.html#equation-update">(3)</a>, taking the form</p>
<div class="math notranslate nohighlight" id="equation-sequential-update">
<span class="eqno">(22)<a class="headerlink" href="#equation-sequential-update" title="Permalink to this equation">¶</a></span>\[\Delta \epsilon_l^{(i)}(t) \propto
    \Im \big\langle
    \chi_k^{(i-1)}(t)
    \big\vert
    \Op{\mu}
    \big\vert
    \phi_k^{(i)}(t)
    \big\rangle\,,\]</div>
<p>with co-states <span class="math notranslate nohighlight">\(\ket{\chi_k(t)^{(i-1)}}\)</span> backward-propagated
under the <em>guess</em> controls <span class="math notranslate nohighlight">\(\{\epsilon_l^{(i-1)}(t)\}\)</span> and the
states <span class="math notranslate nohighlight">\(\ket{\phi^{(i)}_k(t)}\)</span> forward-propagated under the
<em>optimized</em> controls <span class="math notranslate nohighlight">\(\{\epsilon_l^{(i)}(t)\}\)</span>. Compared to the
<em>concurrent</em> form of
Eq. <a class="reference internal" href="#equation-concurrent-update">(20)</a>, the Krotov
update scheme is <em>sequential</em>: The update at time <span class="math notranslate nohighlight">\(t\)</span> depends on
the states forward-propagated using the updated controls at all previous
times, see <a class="reference internal" href="07_krotovs_method.html#timediscretization"><span class="std std-ref">Time discretization</span></a>
for details.</p>
<p>It is worth noting that the sequential update can be recovered as a
limiting case of the monotonically convergent class of algorithms in
Eq. <a class="reference internal" href="#equation-zhu-rabitz-update">(21)</a>, for
<span class="math notranslate nohighlight">\(\delta = 1\)</span>, <span class="math notranslate nohighlight">\(\eta = 0\)</span>. This may explain why parts of the
quantum control community consider <em>any</em> sequential update scheme as
“Krotov’s method” <a class="bibtex reference internal" href="99_bibliography.html#schirmernjp2011" id="id24">[70]</a><a class="bibtex reference internal" href="99_bibliography.html#machnespra11" id="id25">[71]</a>.
However, following Krotov’s
construction <a class="bibtex reference internal" href="99_bibliography.html#krotovec1983" id="id26">[40]</a><a class="bibtex reference internal" href="99_bibliography.html#krotovcc1988" id="id27">[41]</a><a class="bibtex reference internal" href="99_bibliography.html#krotov-book" id="id28">[42]</a><a class="bibtex reference internal" href="99_bibliography.html#konnovarc99" id="id29">[43]</a>
requires no ad-hoc modification of the functional and can thus be
applied more generally. In particular, as discussed in
<a class="reference internal" href="07_krotovs_method.html#secondorderupdate"><span class="std std-ref">Second order update</span></a>, a second-order construction can address non-convex
functionals.</p>
<p>In all its
variants <a class="bibtex reference internal" href="99_bibliography.html#tannor92" id="id30">[5]</a><a class="bibtex reference internal" href="99_bibliography.html#somloicp1993" id="id31">[44]</a><a class="bibtex reference internal" href="99_bibliography.html#bartanajcp1997" id="id32">[45]</a><a class="bibtex reference internal" href="99_bibliography.html#sklarzpra2002" id="id33">[46]</a><a class="bibtex reference internal" href="99_bibliography.html#reichjcp12" id="id34">[22]</a>,
Krotov’s method is a first-order gradient with respect to the control
fields (even in the second-order construction which is second order only
with respect to the states). As the optimization approaches the optimum,
this gradient can become very small, resulting in slow convergence. It
is possible to extend Krotov’s method to take into account information
from the quasi-Hessian <a class="bibtex reference internal" href="99_bibliography.html#eitanpra11" id="id35">[23]</a>. However, this
“K-BFGS” variant of Krotov’s method is a substantial extension to the
procedure as described in <a class="reference internal" href="07_krotovs_method.html#krotovsmethod"><span class="std std-ref">Krotov’s Method</span></a>, and is currently not
supported by the <a class="reference internal" href="API/krotov.html#module-krotov" title="krotov"><code class="xref py py-mod docutils literal notranslate"><span class="pre">krotov</span></code></a> package.</p>
<p>The update Eq. <a class="reference internal" href="#equation-sequential-update">(22)</a> is
specific to the running cost in Eq. <a class="reference internal" href="07_krotovs_method.html#equation-g-a">(2)</a>. In most of
the <a class="reference internal" href="#iterativeschemes"><span class="std std-ref">Iterative schemes from variational calculus</span></a>, a constraint
on the <em>pulse fluence</em> is used instead. Formally, this is also
compatible with Krotov’s method, by choosing
<span class="math notranslate nohighlight">\(\epsilon_{l, \text{ref}}^{(i)}(t) \equiv 0\)</span> in
Eq. <a class="reference internal" href="07_krotovs_method.html#equation-g-a">(2)</a> <a class="bibtex reference internal" href="99_bibliography.html#palaoprl2002" id="id36">[72]</a>. It turns
the <em>update</em> equations <a class="reference internal" href="#equation-sequential-update">(22)</a>, <a class="reference internal" href="#equation-concurrent-update">(20)</a>
into <em>replacement</em> equations, with <span class="math notranslate nohighlight">\(\epsilon_l^{(i)}(t)\)</span> on the
left-hand side instead of <span class="math notranslate nohighlight">\(\Delta\epsilon_l^{(i)}(t)\)</span>,
cf. Eq. <a class="reference internal" href="#equation-zhu-rabitz-update">(21)</a> for
<span class="math notranslate nohighlight">\(\delta = 1\)</span>, <span class="math notranslate nohighlight">\(\eta = 0\)</span>. In our experience, this leads to
numerical instability and should be avoided. A mixture of <em>update</em> and
<em>replacement</em> is possible when a penalty of the pulse fluence is
necessary <a class="bibtex reference internal" href="99_bibliography.html#goerzphd2015" id="id37">[73]</a>.</p>
</div>
<div class="section" id="gradient-ascent-pulse-engineering-grape">
<span id="grape"></span><h2>GRadient Ascent Pulse Engineering (GRAPE)<a class="headerlink" href="#gradient-ascent-pulse-engineering-grape" title="Permalink to this headline">¶</a></h2>
<p>While the monotonically convergent methods based on variational calculus
must “guess” the appropriate time discretization, and Krotov’s method
finds the sequential time discretization by a clever construction, the
GRAPE method sidesteps the problem by discretizing the functional
<em>first</em>, before applying the variational calculus.</p>
<p>Specifically, we consider the piecewise-constant discretization of the
dynamics onto a time grid, where the final time states
<span class="math notranslate nohighlight">\(\{\ket{\phi_k^{(i-1)}(T)}\}\)</span> resulting from the time evolution of
the initial states <span class="math notranslate nohighlight">\(\{\ket{\phi_k}\}\)</span> under the guess controls
<span class="math notranslate nohighlight">\(\epsilon^{(i-1)}_n\)</span> in iteration <span class="math notranslate nohighlight">\((i)\)</span> of the optimization
are obtained as</p>
<div class="math notranslate nohighlight" id="equation-discrete-time-evolution">
<span class="eqno">(23)<a class="headerlink" href="#equation-discrete-time-evolution" title="Permalink to this equation">¶</a></span>\[\ket{\phi^{(i-1)}_k(T)} = \Op{U}^{(i-1)}_{N_T} \dots
\Op{U}^{(i-1)}_{n} \dots \Op{U}^{(i-1)}_{1} \big\vert \phi_k \big\rangle\,,\]</div>
<p>where <span class="math notranslate nohighlight">\(\Op{U}^{(i-1)}_{n}\)</span> is the time evolution operator on the
time interval <span class="math notranslate nohighlight">\(n\)</span> in Hilbert space,</p>
<div class="math notranslate nohighlight">
\[\Op{U}^{(i-1)}_{n} = \exp\Bigg[ -\frac{\mathrm{i}}{\hbar} \Op{H}\big(
\underbrace{\epsilon^{(i-1)}(\tilde t_{n-1})}_{\epsilon^{(i-1)}_n} \big) \dd
t\Bigg];\qquad \tilde{t}_n \equiv t_n + \dd t / 2\,.\]</div>
<p>The independent control parameters are now the scalar values
<span class="math notranslate nohighlight">\(\epsilon_n\)</span>, respectively <span class="math notranslate nohighlight">\(\epsilon_{ln}\)</span> if there are
multiple control fields indexed by <span class="math notranslate nohighlight">\(l\)</span>.</p>
<p>The GRAPE method looks at the direct gradient
<span class="math notranslate nohighlight">\(\partial J/\partial \epsilon_n\)</span> and updates each control
parameter in the direction of that
gradient <a class="bibtex reference internal" href="99_bibliography.html#khanejajmr05" id="id38">[21]</a>. The step width must be
determined by a line search.</p>
<p>Typically, only the final time functional <span class="math notranslate nohighlight">\(J_T\)</span> has a nontrivial
gradient. For simplicity, we assume that <span class="math notranslate nohighlight">\(J_T\)</span> can be expressed in
terms of the complex overlaps <span class="math notranslate nohighlight">\(\{\tau_k\}\)</span> between the target
states <span class="math notranslate nohighlight">\(\{\ket{\phi_k^{\tgt}}\}\)</span> and the propagated states
<span class="math notranslate nohighlight">\(\{\ket{\phi_k(T)}\}\)</span>, as e.g. in
Eqs. <a class="reference internal" href="07_krotovs_method.html#equation-jtss">(5)</a>, <a class="reference internal" href="07_krotovs_method.html#equation-jtre">(7)</a>. Using Eq. <a class="reference internal" href="#equation-discrete-time-evolution">(23)</a>
leads to</p>
<div class="math notranslate nohighlight" id="equation-gradient">
<span class="eqno">(24)<a class="headerlink" href="#equation-gradient" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
  \frac{\partial \tau_k}{\partial \epsilon_n} &amp;= \frac{\partial}{\partial
  \epsilon_n} \big\langle \phi_k^{\tgt} \big\vert \Op{U}^{(i-1)}_{N_T} \dots
  \Op{U}^{(i-1)}_{n} \dots \Op{U}^{(i-1)}_{1} \big\vert \phi_k \big\rangle \\
  &amp;=
      \underbrace{%
  \big\langle \phi_k^{\tgt} \big\vert
            \Op{U}^{(i-1)}_{N_T} \dots \Op{U}^{(i-1)}_{n+1}}_{%
  \bra{\chi^{(i-1)}_k(t_{n+1})} } \,
  \frac{\partial\Op{U}^{(i-1)}_{n}}{\partial\epsilon_n} \,
       \underbrace{%
  \Op{U}^{(i-1)}_{n-1} \dots \Op{U}^{(i-1)}_{1} \big\vert
          \phi_k \big\rangle}_{%
  \ket{\phi^{(i-1)}_k(t_n)} }\
\end{split}\end{split}\]</div>
<p>as the gradient of these overlaps. The gradient for <span class="math notranslate nohighlight">\(J_T\)</span>,
respectively <span class="math notranslate nohighlight">\(J\)</span> if there are additional running costs then
follows from the chain rule. The numerical evaluation of
Eq. <a class="reference internal" href="#equation-gradient">(24)</a> involves the backward-propagated
states <span class="math notranslate nohighlight">\(\ket{\chi_k(t_{n+1})}\)</span> and the forward-propagated states
<span class="math notranslate nohighlight">\(\ket{\phi_k(t_n)}\)</span>. As only states from iteration <span class="math notranslate nohighlight">\((i-1)\)</span>
enter in the gradient, GRAPE is a <em>concurrent</em> scheme.</p>
<p>The comparison of the sequential update
equation <a class="reference internal" href="#equation-sequential-update">(22)</a> of
Krotov’s method and the concurrent update
equation <a class="reference internal" href="#equation-concurrent-update">(20)</a> has
inspired a sequential evaluation of the “gradient”, modifying the
right-hand side of Eq. <a class="reference internal" href="#equation-gradient">(24)</a> to
<span class="math notranslate nohighlight">\(\langle \chi_k^{(i-1)}(t_{n+1})
\vert \partial_\epsilon U_n^{(i-1)} \vert \phi_k^{(i)}(t_n)\rangle\)</span>.
That is, the states <span class="math notranslate nohighlight">\(\{\ket{\phi_k(t)}\}\)</span> are forward-propagated
under the optimized field <a class="bibtex reference internal" href="99_bibliography.html#schirmerjmo2009" id="id39">[74]</a>. This can
be generalized to “hybrid” schemes that interleave concurrent and
sequential calculation of the gradient <a class="bibtex reference internal" href="99_bibliography.html#machnespra11" id="id40">[71]</a>.
An implementation of the concurrent/sequential/hybrid gradient is
available in the <a class="reference external" href="https://github.com/shaimach/Dynamo">DYNAMO Matlab package</a> <a class="bibtex reference internal" href="99_bibliography.html#machnespra11" id="id41">[71]</a>.
The sequential gradient scheme is sometimes referred to as
“Krotov-type” <a class="bibtex reference internal" href="99_bibliography.html#machnespra11" id="id42">[71]</a><a class="bibtex reference internal" href="99_bibliography.html#floethernjp12" id="id43">[75]</a>. To avoid
confusion with the specific method defined in
<a class="reference internal" href="07_krotovs_method.html#krotovsmethod"><span class="std std-ref">Krotov’s Method</span></a>, we prefer the name “sequential GRAPE”.</p>
<p>GRAPE does not give a guarantee of monotonic convergence. As the
optimization approaches the minimum of the functional, the first order
gradient is generally insufficient to drive the optimization
further <a class="bibtex reference internal" href="99_bibliography.html#eitanpra11" id="id44">[23]</a>. To remedy this, a numerical
estimate of the Hessian <span class="math notranslate nohighlight">\(\partial^2 J_T/\partial
\epsilon_j \partial \epsilon_{j^\prime}\)</span> should also be included in the
calculation of the update. The <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html">L-BFGS-B</a> quasi-Newton
method <a class="bibtex reference internal" href="99_bibliography.html#byrdsjsc1995" id="id45">[76]</a><a class="bibtex reference internal" href="99_bibliography.html#zhuatms97" id="id46">[77]</a> is most commonly used
for this purpose, resulting in the “Second-order
GRAPE” <a class="bibtex reference internal" href="99_bibliography.html#fouquieresjmr2011" id="id47">[78]</a> or “GRAPE-LBFGS” method.
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html">L-BFGS-B</a> is implemented as a Fortran
library <a class="bibtex reference internal" href="99_bibliography.html#zhuatms97" id="id48">[77]</a> and widely available, e.g. wrapped
in optimization toolboxes like <a class="reference external" href="https://www.scipy.org">SciPy</a> <a class="bibtex reference internal" href="99_bibliography.html#scipy" id="id49">[79]</a>. This
means that it can be easily added as a “black box” to an existing
gradient optimization. As a result, augmenting GRAPE with a
quasi-Hessian is essentially “for free”. Thus, we always mean GRAPE to
refer to GRAPE-LBFGS. Empirically, GRAPE-LBFGS <em>usually</em> converges
monotonically.</p>
<p>Thus, for (discretized) time-continuous controls, both GRAPE and
Krotov’s method can generally be used interchangeably. Historically,
Krotov’s method has been used primarily in the control of molecular
dynamics, while GRAPE has been popular in the NMR community. Some
potential benefits of Krotov’s method compared to GRAPE
are <a class="bibtex reference internal" href="99_bibliography.html#eitanpra11" id="id50">[23]</a>:</p>
<ul class="simple">
<li><p>Krotov’s method mathematically guarantees monotonic convergence in
the continuous-time limit. There is no line-search required for the
step width <span class="math notranslate nohighlight">\(1 / \lambda_{a, l}\)</span>.</p></li>
<li><p>The sequential nature of Krotov’s update scheme, with information
from earlier times entering the update at later times within the same
iteration, results in faster convergence than the concurrent update
in GRAPE <a class="bibtex reference internal" href="99_bibliography.html#machnespra11" id="id51">[71]</a><a class="bibtex reference internal" href="99_bibliography.html#jaegerpra14" id="id52">[80]</a>. This advantage
disappears as the optimization approaches the
optimum <a class="bibtex reference internal" href="99_bibliography.html#eitanpra11" id="id53">[23]</a>.</p></li>
<li><p>The choice of functional <span class="math notranslate nohighlight">\(J_T\)</span> in Krotov’s method only enters
in the boundary condition for the backward-propagated states,
Eq. <a class="reference internal" href="07_krotovs_method.html#equation-chi-boundary">(15)</a>, while the update
equation stays the same otherwise. In contrast, for functionals
<span class="math notranslate nohighlight">\(J_T\)</span> that do not depend trivially on the
overlaps <a class="bibtex reference internal" href="99_bibliography.html#nevesjmr2009" id="id54">[81]</a><a class="bibtex reference internal" href="99_bibliography.html#nguyenjmr2017" id="id55">[82]</a><a class="bibtex reference internal" href="99_bibliography.html#anselpra2017" id="id56">[83]</a><a class="bibtex reference internal" href="99_bibliography.html#spindlerjmr2012" id="id57">[84]</a><a class="bibtex reference internal" href="99_bibliography.html#tosneracie2018" id="id58">[85]</a>,
the evaluation of the gradient in GRAPE may deviate significantly
from its usual form, requiring a problem-specific implementation from
scratch. This may be mitigated by the use of automatic
differentiation in future
implementations <a class="bibtex reference internal" href="99_bibliography.html#leungpra2017" id="id59">[86]</a><a class="bibtex reference internal" href="99_bibliography.html#abdelhafezpra2019" id="id60">[87]</a>.</p></li>
</ul>
<p>GRAPE has a significant advantage if the controls are not
time-continuous, but are <em>physically</em> piecewise constant (“bang-bang
control”). The calculation of the GRAPE-gradient is unaffected by this,
whereas Krotov’s method can break down when the controls are not
approximately continuous. QuTiP contains an implementation of GRAPE
limited to this use case.</p>
<p>Variants of gradient-ascent can be used to address <em>pulse
parametrizations</em>. That is, the control parameters may be arbitrary
parameters of the control field (e.g., spectral coefficients) instead of
the field amplitude <span class="math notranslate nohighlight">\(\epsilon_n\)</span> in a particular time interval.
This is often relevant to design control fields that meet experimental
constraints. One possible realization is to calculate the gradients for
the control parameters from the gradients of the time-discrete control
amplitudes via the chain
rule <a class="bibtex reference internal" href="99_bibliography.html#winckelip2008" id="id61">[88]</a><a class="bibtex reference internal" href="99_bibliography.html#skinnerjmr2010" id="id62">[89]</a><a class="bibtex reference internal" href="99_bibliography.html#motzoipra2011" id="id63">[90]</a><a class="bibtex reference internal" href="99_bibliography.html#lucarellipra2018" id="id64">[91]</a>.
This approach
has recently been named “GRadient Optimization Using Parametrization”
(GROUP) <a class="bibtex reference internal" href="99_bibliography.html#sorensenpra2018" id="id65">[92]</a>.
An implementation of several variants of GROUP is available in the
QEngine C++ library <a class="bibtex reference internal" href="99_bibliography.html#sorensencpc2019" id="id66">[93]</a>.
An alternative for a
moderate number of control parameters is “gradient-optimization of
analytic controls” (GOAT) <a class="bibtex reference internal" href="99_bibliography.html#machnesprl2018" id="id67">[94]</a>. GOAT
evaluates the relevant gradient with forward-mode differentiation; that
is, <span class="math notranslate nohighlight">\({\partial \tau_k}/{\partial \epsilon_n}\)</span> is directly
evaluated alongside <span class="math notranslate nohighlight">\(\tau_k\)</span>. For <span class="math notranslate nohighlight">\(N = \Abs{\{\epsilon_m\}}\)</span>
control parameters, this implies <span class="math notranslate nohighlight">\(N\)</span> forward propagations of the
state-gradient pair per iteration. Alternatively, the <span class="math notranslate nohighlight">\(N\)</span>
propagations can be concatenated into a single propagation in a Hilbert
space enlarged by a factor <span class="math notranslate nohighlight">\(N\)</span> (the original state paired with
<span class="math notranslate nohighlight">\(N\)</span> gradients).</p>
<p>A benefit of GOAT over the more general GROUP is that it does not
piggy-back on the piecewise-constant discretization of the control
field, and thus may avoid the associated numerical error. This allows to
optimize to extremely high fidelities as required for some error
correction protocols <a class="bibtex reference internal" href="99_bibliography.html#machnesprl2018" id="id68">[94]</a>.</p>
</div>
<div class="section" id="grape-in-qutip">
<span id="grapeinqutip"></span><h2>GRAPE in QuTiP<a class="headerlink" href="#grape-in-qutip" title="Permalink to this headline">¶</a></h2>
<p>An implementation of GRAPE is included in QuTiP, see the <a class="reference external" href="http://qutip.org/docs/latest/guide/guide-control.html">section on Quantum
Optimal Control in the QuTiP docs</a>.  It is used via the
<a class="reference external" href="http://qutip.org/docs/latest/apidoc/functions.html#qutip.control.pulseoptim.optimize_pulse" title="(in QuTiP: Quantum Toolbox in Python v4.4)"><code class="xref py py-func docutils literal notranslate"><span class="pre">qutip.control.pulseoptim.optimize_pulse()</span></code></a> function.
However, some of the design choices in QuTiP’s GRAPE effectively limit
the routine to applications with physically piecewise-constant pulses (where
GRAPE has an advantage over Krotov’s method, as discussed in the previous
section).</p>
<p>For discretized time-continuous pulses, the implementation of Krotov’s method
in <a class="reference internal" href="API/krotov.optimize.html#krotov.optimize.optimize_pulses" title="krotov.optimize.optimize_pulses"><code class="xref py py-func docutils literal notranslate"><span class="pre">optimize_pulses()</span></code></a> has the following advantages over
<a class="reference external" href="http://qutip.org/docs/latest/apidoc/functions.html#qutip.control.pulseoptim.optimize_pulse" title="(in QuTiP: Quantum Toolbox in Python v4.4)"><code class="xref py py-func docutils literal notranslate"><span class="pre">qutip.control.pulseoptim.optimize_pulse()</span></code></a>:</p>
<ul class="simple">
<li><p>Krotov’s method can optimize for more than one control field at the same time
(hence the name of the routine <a class="reference internal" href="API/krotov.optimize.html#krotov.optimize.optimize_pulses" title="krotov.optimize.optimize_pulses"><code class="xref py py-func docutils literal notranslate"><span class="pre">optimize_pulses()</span></code></a> compared to
<a class="reference external" href="http://qutip.org/docs/latest/apidoc/functions.html#qutip.control.pulseoptim.optimize_pulse" title="(in QuTiP: Quantum Toolbox in Python v4.4)"><code class="xref py py-func docutils literal notranslate"><span class="pre">optimize_pulse()</span></code></a>).</p></li>
<li><p>Krotov’s method optimizes a list of <a class="reference internal" href="API/krotov.objectives.html#krotov.objectives.Objective" title="krotov.objectives.Objective"><code class="xref py py-class docutils literal notranslate"><span class="pre">Objective</span></code></a> instances
simultaneously. The optimization for multiple simultaneous objectives in
QuTiP’s GRAPE implementation is limited to optimizing a quantum gate. Other
uses of simultaneous objectives, such as optimizing for robustness, are not
available.</p></li>
<li><p>Krotov’s method can start from an arbitrary set of guess controls. In the
GRAPE implementation, guess pulses can only be chosen from a specific set of
options (including “random”). Again, this makes sense for a control field
that is piecewise constant with relatively few switching points, but is very
disadvantageous for time-continuous controls.</p></li>
<li><p>Krotov’s method has complete flexibility in which propagation method is used
(via the <cite>propagator</cite> argument to <a class="reference internal" href="API/krotov.optimize.html#krotov.optimize.optimize_pulses" title="krotov.optimize.optimize_pulses"><code class="xref py py-func docutils literal notranslate"><span class="pre">optimize_pulses()</span></code></a>), while QuTiP’s
GRAPE only allows to choose between fixed number of methods for
time-propagation. Supplying a problem-specific propagator is not possible.</p></li>
</ul>
<p>Thus, QuTiP’s GRAPE implementation and the implementation of Krotov’s method in
this package complement each other, but will not compare directly.</p>
</div>
<div class="section" id="gradient-free-optimization">
<span id="gradientfreeoptimization"></span><h2>Gradient-free optimization<a class="headerlink" href="#gradient-free-optimization" title="Permalink to this headline">¶</a></h2>
<p>In situations where the problem can be reduced to a relatively small
number of control parameters (typically less than <span class="math notranslate nohighlight">\(\approx20\)</span>,
although this number may be pushed to <span class="math notranslate nohighlight">\(\approx50\)</span> by sequential
increase of the number of parameters and
re-parametrization <a class="bibtex reference internal" href="99_bibliography.html#rachpra2015" id="id69">[95]</a><a class="bibtex reference internal" href="99_bibliography.html#goetzpra2016" id="id70">[96]</a>),
gradient-free optimization becomes feasible. The most straightforward
use case are controls with an analytic shape (e.g. due to the
constraints of an experimental setup), with just a few free parameters.
As an example, consider control pulses that are restricted to a Gaussian
shape, so that the only free parameters are peak amplitude, pulse width
and delay. The control parameters are not required to be parameters of a
time-dependent control, but may also be static parameters in the
Hamiltonian, e.g. the polarization of the laser beams utilized in an
experiment <a class="bibtex reference internal" href="99_bibliography.html#hornnjp2018" id="id71">[97]</a>.</p>
<p>A special case of gradient-free optimization is the Chopped RAndom Basis
(CRAB) method <a class="bibtex reference internal" href="99_bibliography.html#doriaprl11" id="id72">[98]</a><a class="bibtex reference internal" href="99_bibliography.html#canevapra2011" id="id73">[99]</a>. The essence
of CRAB is in the specific choice of the parametrization in terms of a
low-dimensional <em>random</em> basis, as the name implies. Thus, it can be
used when the parametrization is not pre-defined as in the case of
direct free parameters in the pulse shape discussed above. The
optimization itself is normally performed by Nelder-Mead simplex based
on this parametrization, although any other gradient-free method could
be used as well. An implementation of CRAB is available in QuTiP, see <a class="reference external" href="http://qutip.org/docs/latest/guide/guide-control.html#the-crab-algorithm">QuTiP’s
documentation of CRAB</a>, and uses the same
<a class="reference external" href="http://qutip.org/docs/latest/apidoc/functions.html#qutip.control.pulseoptim.optimize_pulse" title="(in QuTiP: Quantum Toolbox in Python v4.4)"><code class="xref py py-func docutils literal notranslate"><span class="pre">qutip.control.pulseoptim.optimize_pulse()</span></code></a>
interface as the GRAPE method discussed above (<a class="reference internal" href="#grapeinqutip"><span class="std std-ref">GRAPE in QuTiP</span></a>) with the
same limitations.
CRAB is prone to getting stuck in local minima of the optimization landscape.
To remedy this, a variant of CRAB, “dressed CRAB” (DCRAB) has been
developed <a class="bibtex reference internal" href="99_bibliography.html#rachpra2015" id="id74">[95]</a> that re-parametrizes the controls when this
happens.</p>
<p>Gradient-free optimization does not require backward propagation, only
forward propagation of the initial states and evaluation of the
optimization functional <span class="math notranslate nohighlight">\(J\)</span>. The functional is not required to be
analytic. It may be of a form that does not allow calculation of the
gradients <span class="math notranslate nohighlight">\(\partial
J_T / \partial \bra{\phi_k}\)</span> (Krotov’s method) or
<span class="math notranslate nohighlight">\(\partial J / \partial
\epsilon_j\)</span> (GRAPE). The optimization also does not require any storage
of states. However, the number of iterations can grow extremely large,
especially with an increasing number of control parameters. Thus, an
optimization with a gradient-free method is not necessarily more
efficient overall compared to a gradient-based optimization with much
faster convergence. For only a few parameters, however, it can be highly
efficient. This makes gradient-free optimization useful for
“pre-optimization”, that is, for finding guess controls that are then
further optimized with a gradient-based
method <a class="bibtex reference internal" href="99_bibliography.html#goerzepjqt2015" id="id75">[32]</a>.</p>
<p>Generally, gradient-free optimization can be easily realized directly in
QuTiP or any other software package for the simulation of quantum
dynamics:</p>
<ul class="simple">
<li><p>Write a function that takes an array of optimization parameters as
input and returns a figure of merit. This function would, e.g.,
construct a numerical control pulse from the control parameters,
simulate the dynamics using qutip.mesolve.mesolve, and evaluate a
figure of merit (like the overlap with a target state).</p></li>
<li><p>Pass the function to scipy.optimize.minimize for gradient-free
optimization.</p></li>
</ul>
<p>The implementation in <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize" title="(in SciPy v1.3.3)"><code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.optimize.minimize()</span></code></a> allows to choose between
different optimization methods, with Nelder-Mead simplex being the
default. There exist also more advanced optimization methods available
in packages like <a class="reference external" href="https://nlopt.readthedocs.io/">NLopt</a> <a class="bibtex reference internal" href="99_bibliography.html#nlopt" id="id76">[100]</a> or
<a class="reference external" href="https://github.com/facebookresearch/nevergrad">Nevergrad</a> <a class="bibtex reference internal" href="99_bibliography.html#nevergrad" id="id77">[101]</a> that may be worth exploring for
improvements in numerical efficiency and additional functionality such
as support for non-linear constraints.</p>
</div>
<div class="section" id="choosing-an-optimization-method">
<span id="id78"></span><h2>Choosing an optimization method<a class="headerlink" href="#choosing-an-optimization-method" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="id90">
<span id="figoctdecisiontree"></span><a class="reference internal image-reference" href="_images/oct_decision_tree.svg"><img alt="OCT decision tree." src="_images/oct_decision_tree.svg" width="100%" /></a>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Decision tree for the choice of a numerical open-loop
optimization method.
The choice of control method is most directly associated with the number of
control parameters (<span class="math notranslate nohighlight">\(n\)</span>).
For “piecewise-constant controls”, the control
parameters are the values of the control field in each time interval.
For “analytical” controls, we assume that the control fields are
described by a fixed analytical formula parametrized by the control
parameters. The “non-analytical” controls for CRAB refer to the
<em>random</em> choice of a fixed number of spectral components, where the
control parameters are the coefficients for those spectral
components. Each method in the diagram is meant to include all its
variants, a multitude of gradient-free methods and e.g. DCRAB for
CRAB, GRAPE-LBFGS and sequential/hybrid gradient-descent for GRAPE,
and K-BFGS for Krotov’s method, see text for detail.</span><a class="headerlink" href="#id90" title="Permalink to this image">¶</a></p>
</div>
<p>In the following, we discuss some of the concerns in the choice of
optimization methods. The discussion is limited to iterative open-loop
methods, where the optimization is based on a numerical simulation of
the dynamics. It excludes analytical control methods such as geometric
control, closed-loop methods, or coherent feedback control; see
Ref. <a class="bibtex reference internal" href="99_bibliography.html#petersenietcta2010" id="id79">[102]</a> for an overview.</p>
<p>Whether to use a gradient-free optimization method, GRAPE, or Krotov’s
method depends on the size of the problem, the requirements on the
control fields, and the mathematical properties of the optimization
functional. Gradient-free methods should be used if the number of
independent control parameters is smaller than <span class="math notranslate nohighlight">\(\approx 20\)</span>, or
the functional is of a form that does not allow to calculate gradients
easily. It is always a good idea to use a gradient-free method to obtain
improved guess pulses for use with a gradient-based
method <a class="bibtex reference internal" href="99_bibliography.html#goerzepjqt2015" id="id80">[32]</a>.</p>
<p>GRAPE or its variants should be used if the control parameters are
discrete, such as on a coarse-grained time grid, and the derivative of
<span class="math notranslate nohighlight">\(J\)</span> with respect to each control parameter is easily computable.
Note that the implementation provided in QuTiP is limited to
state-to-state transitions and quantum gates, even though the method is
generally applicable to a wider range of objectives.</p>
<p>When the control parameters are general analytic coefficients instead of
time-discrete amplitudes, the
GROUP <a class="bibtex reference internal" href="99_bibliography.html#skinnerjmr2010" id="id81">[89]</a><a class="bibtex reference internal" href="99_bibliography.html#motzoipra2011" id="id82">[90]</a><a class="bibtex reference internal" href="99_bibliography.html#sorensenpra2018" id="id83">[92]</a> or
GOAT <a class="bibtex reference internal" href="99_bibliography.html#machnesprl2018" id="id84">[94]</a> variant of gradient-ascent may
be a suitable choice. GOAT in particular can avoid the numerical error
associated with time discretization. However, as the method scales
linearly in memory and/or CPU with the number of control parameters,
this is best used when then number of parameters is below 100.</p>
<p>Krotov’s method should be used if the control is close to
time-continuous, and if the derivative of <span class="math notranslate nohighlight">\(J_T\)</span> with respect to
the states, Eq. <a class="reference internal" href="07_krotovs_method.html#equation-chi-boundary">(15)</a>, can be
calculated. When these conditions are met, Krotov’s method gives
excellent convergence. The general family of monotonically convergent
iteration schemes <a class="bibtex reference internal" href="99_bibliography.html#madayjcp2003" id="id85">[66]</a> may also be used.</p>
<p>The decision tree in <a class="reference internal" href="#figoctdecisiontree"><span class="std std-numref">Fig. 2</span></a> can guide the
choice of an optimization method. The key deciding factors are the
number of control parameters (<span class="math notranslate nohighlight">\(n\)</span>) and whether the controls are time-discrete.
Of course, the parametrization of the controls is itself a choice.
Sometimes, experimental constraints only allow controls that depend on a
small number of tunable parameters. However, this necessarily limits the
exploration of the full physical optimization landscape. At the other
end of the spectrum, arbitrary time-continuous controls such as those
assumed in Krotov’s method have no inherent constraints and are
especially useful for more fundamental tasks, such as mapping the design
landscape of a particular system <a class="bibtex reference internal" href="99_bibliography.html#goerznpjqi2017" id="id86">[103]</a> or
determining the quantum speed limit, i.e., the minimum time in which the
system can reach a given target <a class="bibtex reference internal" href="99_bibliography.html#canevaprl09" id="id87">[104]</a><a class="bibtex reference internal" href="99_bibliography.html#goerzjpb11" id="id88">[105]</a><a class="bibtex reference internal" href="99_bibliography.html#sorensennat16" id="id89">[15]</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="12_related_software.html" class="btn btn-neutral float-right" title="Related Software" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="10_howto.html" class="btn btn-neutral float-left" title="How-Tos" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Michael Goerz et al.
      <span class="lastupdated">
        Last updated on Dec 16, 2019.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>